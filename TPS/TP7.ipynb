{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1781485d-caeb-44c6-87f7-1cc39b1d251b",
   "metadata": {},
   "source": [
    "#### Charger ce dataset.\n",
    "#### Utiliser les méthodes usuelles de pandas pour obtenir les informations de base sur ce dataset (nombre d'observations et de variables, types des variables, valeurs manquantes, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755c16bd-9752-48f4-86f9-9c018dab0fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'worldBank.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworldBank.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNombre d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservations et de variables \u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mD:\\supinfo\\M1\\EDAP\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\supinfo\\M1\\EDAP\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\supinfo\\M1\\EDAP\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\supinfo\\M1\\EDAP\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\supinfo\\M1\\EDAP\\env\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'worldBank.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('worldBank.csv')\n",
    "print(df.head())\n",
    "\n",
    "print(\"Nombre d'observations et de variables \", df.shape)\n",
    "print(\"\\nTypes des variables \")\n",
    "print(df.dtypes)\n",
    "print(\"\\nValeurs manquantes\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f2ee1-805e-4217-a98f-7367f520202d",
   "metadata": {},
   "source": [
    "#### Combien de valeurs sont manquantes sur l'ensemble du dataset ? Faire une suppression par liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39629155-8db3-4beb-a0cc-9ec3de20391f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_manq = df.isnull().sum().sum()\n",
    "print(\"Nombre total de valeurs manquantes sur l'ensemble du dataset est\", val_manq)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aa695e-82ba-4d52-aa94-9b380195a45d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique=df['Series Code'].unique()\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d554431-870f-4033-bf0f-af75007bc13f",
   "metadata": {},
   "source": [
    "#### Mettre ce dataset sous forme 'tidy' en créant deux variables 'Population' et 'Surface'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28b00c-7584-4191-ac4f-2d5f4e2abd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique=df['Series Name'].unique()\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bd629-db40-48d5-8dd1-1cf31ac5d721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "population_df = df[df['Series Name'] == 'Population, total']\n",
    "surface_df = df[df['Series Name'] == 'Surface area (sq. km)']\n",
    "\n",
    "#valeurs de Population et Surface\n",
    "population_df.rename(columns={'2018 [YR2018]': 'Population'}, inplace=True)\n",
    "surface_df.rename(columns={'2018 [YR2018]': 'Surface'}, inplace=True)\n",
    "\n",
    "# Fusionnant les deux df \n",
    "tidy_df = pd.merge(population_df[['Country Name', 'Country Code', 'Population']], \n",
    "                   surface_df[['Country Name', 'Country Code', 'Surface']], \n",
    "                   on=['Country Name', 'Country Code'])\n",
    "\n",
    "print(tidy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5110fd-4753-407b-a187-d7d13e9dbdd9",
   "metadata": {},
   "source": [
    "#### Ajouter une variable égale au premier chiffre significatif de la variable 'Population'. On pourra utiliser la méthode 'apply' de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ce36c-1c92-4457-a20c-053313228dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#variable pour le premier chiffre significatif de 'Population'\n",
    "tidy_df['pop_new'] = tidy_df['Population'].apply(lambda x: \n",
    "                                                 int(str(x)[0]) if pd.notnull(x) and '..' not in str(x) \n",
    "                                                 else None )\n",
    "\n",
    "#variable pour le premier chiffre significatif de 'Surface'\n",
    "tidy_df['surf_new'] = tidy_df['Surface'].apply(lambda x: \n",
    "                                                 int(str(x)[0]) if pd.notnull(x) and '..' not in str(x) \n",
    "                                                 else None)\n",
    "print(tidy_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b6d73-9f70-422c-8c0a-b7540312c989",
   "metadata": {},
   "source": [
    "#### Étudier ces variables avec des tables des effectifs et fréquences et des diagrammes en barres. A quel type de loi aurait-on pu s'attendre ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f38f22-6f11-4ff6-8f8b-5174e02adf0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#table des effectifs pour pop_new\n",
    "effectifs_pop = tidy_df['pop_new'].value_counts().sort_index()\n",
    "\n",
    "#table des effectifs pour surf_new\n",
    "effectifs_surf = tidy_df['surf_new'].value_counts().sort_index()\n",
    "\n",
    "#les fréquences pour pop_new\n",
    "freq_pop = effectifs_pop / effectifs_pop.sum()\n",
    "\n",
    "#les fréquences pour surf_new\n",
    "freq_surf = effectifs_surf / effectifs_surf.sum()\n",
    "\n",
    "print(\"Table des effectifs pour pop_new\")\n",
    "print(effectifs_pop)\n",
    "print(\"\\nTable des effectifs pour surf_new\")\n",
    "print(effectifs_surf)\n",
    "\n",
    "print(\"\\nTable des fréquences pour pop_new\")\n",
    "print(freq_pop)\n",
    "print(\"\\nTable des fréquences pour surf_new\")\n",
    "print(freq_surf)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(effectifs_pop.index, effectifs_pop.values)\n",
    "plt.title(\"Effectifs de pop_new\")\n",
    "plt.xlabel(\"Valeurs\")\n",
    "plt.ylabel(\"Effectifs\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(effectifs_surf.index, effectifs_surf.values)\n",
    "plt.title(\"Effectifs de surf_new\")\n",
    "plt.xlabel(\"Valeurs\")\n",
    "plt.ylabel(\"Effectifs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9edd6-9aa2-43a0-b173-c4ee1a3904ac",
   "metadata": {},
   "source": [
    "#### Créer une liste de 9 valeurs où pour 1≤i≤9 la i-ème valeur de cette liste est égale à log10(1+1/i). Vérifier que l'on définit bien ainsi une loi de probabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd08eea-68c8-4a5b-89fe-e3eb91bcea07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Créer une liste vide pour stocker les valeurs\n",
    "liste_valeurs = []\n",
    "\n",
    "# Calculer les valeurs selon la formule pour i de 1 à 9\n",
    "for i in range(1, 10):\n",
    "    valeur = np.log10(1 + 1/i)\n",
    "    liste_valeurs.append(valeur)\n",
    "\n",
    "# Afficher la liste des valeurs\n",
    "print(liste_valeurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3737cfd1-d552-4e8e-a231-466a0802241a",
   "metadata": {},
   "source": [
    "##### Pour vérifier si cela définit bien une loi de probabilité, nous devons nous assurer que toutes les valeurs sont non négatives (car les probabilités sont toujours non négatives) et que la somme de toutes les valeurs est égale à 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c478f7b6-e2d7-438e-82a3-87d4c046f6ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vérifier si toutes les valeurs sont non négatives\n",
    "toutes_positives = all(valeur >= 0 for valeur in liste_valeurs)\n",
    "print(\"Toutes les valeurs sont non négatives :\", toutes_positives)\n",
    "\n",
    "# Vérifier si la somme des valeurs est proche de 1\n",
    "somme_valeurs = sum(liste_valeurs)\n",
    "print(\"Somme des valeurs :\", somme_valeurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b9c64-c385-4733-86f2-e0577a916e11",
   "metadata": {},
   "source": [
    "#### Faire un test d'adéquation du khi-deux entre la variable définie à la question 5 et la loi de probabilité définie à la question 8 (formuler les hypothèses, mener le test à l'aide de la fonction 'chisquare' du module Scipy Stats puis conclure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d37d13-60c5-4035-8f93-be48b4fca3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "# Définition des fréquences observées\n",
    "freq_obs= effectifs_pop\n",
    "freq_obs\n",
    "# # Définition des fréquences attendues selon la loi de probabilité définie à la question 8\n",
    "# total_observations = sum(freq_obs)\n",
    "# freq_attendue = [prob * total_observations for prob in liste_valeurs]\n",
    "\n",
    "# #le test du chi-deux\n",
    "# stat_test, valeur_p = chisquare(freq_obs, f_exp=freq_attendue)\n",
    "\n",
    "# print(\"Chi-deux statistique :\", stat_test)\n",
    "# print(\"P-valeur :\", valeur_p)\n",
    "\n",
    "# # Interprétation des résultats\n",
    "# alpha = 0.05  # Niveau de signification\n",
    "# if valeur_p < alpha:\n",
    "#     print(\"Nous rejetons l'hypothèse nulle : La distribution des premiers chiffres significatifs de la variable 'Population' ne suit pas la loi de probabilité définie à la question 8.\")\n",
    "# else:\n",
    "#     print(\"Nous n'avons pas suffisamment de preuves pour rejeter l'hypothèse nulle : La distribution des premiers chiffres significatifs de la variable 'Population' suit la loi de probabilité définie à la question 8.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a82795-a29a-478b-b7ed-b0846886153e",
   "metadata": {},
   "source": [
    "#### Même question avec la variable de la question 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b4a61-a8b7-43e9-89a8-7d43d0b6b821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "# Définir les fréquences observées\n",
    "observed_frequencies = [len(tidy_df[tidy_df['surf_new'] == i]) for i in range(1, 10)]\n",
    "print (observed_frequencies)\n",
    "# Définir les fréquences attendues selon la loi de probabilité définie à la question 8\n",
    "probabilities = [np.log10(1 + 1/i) for i in range(1, 10)]\n",
    "total_observations = sum(observed_frequencies)\n",
    "expected_frequencies = [prob * total_observations for prob in probabilities]\n",
    "\n",
    "# Effectuer le test du chi-deux\n",
    "chi2_stat, p_value = chisquare(observed_frequencies, f_exp=expected_frequencies)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Chi-deux statistique :\", chi2_stat)\n",
    "print(\"P-valeur :\", p_value)\n",
    "\n",
    "# Interprétation des résultats\n",
    "alpha = 0.05  # Niveau de signification\n",
    "if p_value < alpha:\n",
    "    print(\"Nous rejetons l'hypothèse nulle : La distribution des premiers chiffres significatifs de la variable 'Surface' ne suit pas la loi de probabilité définie à la question 8.\")\n",
    "else:\n",
    "    print(\"Nous n'avons pas suffisamment de preuves pour rejeter l'hypothèse nulle : La distribution des premiers chiffres significatifs de la variable 'Surface' suit la loi de probabilité définie à la question 8.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbdd31-cca3-484a-8548-5ef2faf08b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#les 1000 premiers termes de la suite 2n\n",
    "suite1 = [2**n for n in range(1, 1001)]\n",
    "\n",
    "#le premier chiffre significatif de chaque terme\n",
    "var1 = [int(str(term)[0]) for term in suite1]\n",
    "\n",
    "# les fréquences observées des premiers chiffres significatifs\n",
    "freq_obs = [var1.count(digit) for digit in range(1, 10)]\n",
    "\n",
    "# les fréquences attendues \n",
    "val_attendues = [value * sum(freq_obs) for value in liste_valeurs]\n",
    "\n",
    "#le test du khi-deux\n",
    "chi2_statistic, p_value = chisquare(freq_obs, f_exp=val_attendues)\n",
    "\n",
    "print(\"Statistique du test du khi-deux :\", chi2_statistic)\n",
    "print(\"P-value :\", p_value)\n",
    "\n",
    "# Conclusion\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"La distribution des premiers chiffres significatifs de la suite 2**n ne suit pas la loi de probabilité définie.\")\n",
    "else:\n",
    "    print(\"La distribution des premiers chiffres significatifs de la suite 2**n suit la loi de probabilité définie.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcbc230-008c-429f-a87e-6248772a0ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# Fonction pour calculer la factorielle de n\n",
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)\n",
    "\n",
    "#les premiers termes de la suite n!\n",
    "suite2 = [factorial(n) for n in range(1, 1001)]\n",
    "\n",
    "#le premier chiffre significatif de chaque terme\n",
    "var2 = [int(str(term)[0]) for term in suite2]\n",
    "\n",
    "#les fréquences observées des premiers chiffres significatifs\n",
    "freq_obs = [var2.count(digit) for digit in range(1, 10)]\n",
    "\n",
    "#les fréquences attendues\n",
    "\n",
    "val_attendues = [value * sum(freq_obs) for value in liste_valeurs]\n",
    "\n",
    "# Effectuer le test du khi-deux\n",
    "stat_test, valeur_p = chisquare(freq_obs, f_exp=val_attendues)\n",
    "\n",
    "print(\"Statistique du test du khi-deux :\", stat_test)\n",
    "print(\"P-value :\", valeur_p)\n",
    "\n",
    "# Conclusion\n",
    "alpha = 0.05\n",
    "if valeur_p< alpha:\n",
    "    print(\"La distribution des premiers chiffres significatifs de la suite n! ne suit pas la loi de probabilité définie.\")\n",
    "else:\n",
    "    print(\"La distribution des premiers chiffres significatifs de la suite n! suit la loi de probabilité définie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f0657-4167-4d1a-9b66-4dd07732a693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
